{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"data/kddcup99_train.csv\",on_bad_lines='skip',header=None)\n",
    "test_df = pd.read_csv(\"data/kddcup99_test.csv\",on_bad_lines='skip',header=None)\n",
    "attack_types = pd.read_table(\"data/trainning_attach_types\", header=None,delim_whitespace=True)\n",
    "attack_dict = {attack_types[0][i]+'.':1 for i in range(len(attack_types))}\n",
    "attack_dict['normal.'] = 0\n",
    "# attack_dict\n",
    "train_df[41] = train_df[41].replace(attack_dict)\n",
    "test_df[41] = test_df[41].replace(attack_dict)\n",
    "map_dict = {}\n",
    "for column in train_df.columns:\n",
    "    if pd.api.types.is_object_dtype(train_df[column]):\n",
    "        factorized_column, map = train_df[column].factorize()\n",
    "        train_df[column] = factorized_column\n",
    "        map_dict[column] = {map[i]:i for i in range(len(map))}\n",
    "\n",
    "        _, map_t = test_df[column].factorize()\n",
    "        # print([i for i in map_t if i not in map])\n",
    "map_dict[2]['http_2784']=68\n",
    "map_dict[2]['aol']=69\n",
    "# map_dict\n",
    "for column in test_df.columns:\n",
    "    # print(column)\n",
    "    if column in map_dict.keys():\n",
    "        test_df[column] = test_df[column].replace(map_dict[column])\n",
    "# test_df\n",
    "\n",
    "train_features, train_labels = train_df.iloc[:,:-1], train_df.iloc[:,-1]\n",
    "test_features, test_labels = test_df.iloc[:,:-1], test_df.iloc[:,-1]\n",
    "\n",
    "train_features = train_features.to_numpy()\n",
    "train_labels = train_labels.to_numpy()\n",
    "test_features = test_features.to_numpy()\n",
    "test_labels = test_labels.to_numpy()\n",
    "tensor_x=torch.from_numpy(train_features.astype(np.float32))\n",
    "tensor_y=torch.from_numpy(train_labels.astype(np.float32))\n",
    "my_dataset=TensorDataset(tensor_x,tensor_y)\n",
    "my_dataset_loader=DataLoader(my_dataset,batch_size=2000,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    978649.000000\n",
       "mean          0.801111\n",
       "std           0.399165\n",
       "min           0.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           1.000000\n",
       "max           1.000000\n",
       "Name: 41, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[41].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = train_df.iloc[:,:-1], train_df.iloc[:,-1]\n",
    "test_features, test_labels = test_df.iloc[:,:-1], test_df.iloc[:,-1]\n",
    "\n",
    "train_features = train_features.to_numpy()\n",
    "train_labels = train_labels.to_numpy()\n",
    "test_features = test_features.to_numpy()\n",
    "test_labels = test_labels.to_numpy()\n",
    "tensor_x=torch.from_numpy(train_features.astype(np.float32))\n",
    "tensor_y=torch.from_numpy(train_labels.astype(np.float32))\n",
    "my_dataset=TensorDataset(tensor_x,tensor_y)\n",
    "my_dataset_loader=DataLoader(my_dataset,batch_size=2000,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mynet(nn.Module):\n",
    "    def __init__(self,  act_layer = nn.ReLU(), init_method = nn.init.normal_):\n",
    "        super(mynet, self).__init__()\n",
    "        self.act_layer = act_layer\n",
    "        self.init_method = init_method\n",
    "        self.net = nn.Sequential(\n",
    "            # [b, 41] => [b, rank]\n",
    "            nn.Linear(41, 36),\n",
    "            self.act_layer,\n",
    "            nn.Linear(36, 24),\n",
    "            self.act_layer,\n",
    "            nn.Linear(24, 12),\n",
    "            self.act_layer,\n",
    "            nn.Linear(12, 6),\n",
    "            self.act_layer,\n",
    "            nn.Linear(6, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            self.init_method(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size(0)\n",
    "        x = x.view(batchsize, -1)\n",
    "        x = self.net(x)\n",
    "        # reshape\n",
    "        x = x.view(batchsize, -1)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mynet(\n",
      "  (act_layer): ReLU()\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=41, out_features=36, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=36, out_features=24, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=24, out_features=12, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=12, out_features=6, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=6, out_features=1, bias=True)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n",
      "0\n",
      "246.24953\n"
     ]
    }
   ],
   "source": [
    "def test_train(act_layer = nn.ReLU(), init_method = nn.init.normal_, optimizer = optim.Adam):\n",
    "    epochs = 1\n",
    "    lr = 1e-3\n",
    "    model = mynet(act_layer, init_method)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optimizer(model.parameters(), lr=lr)\n",
    "    print(model)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        total_loss = 0\n",
    "        for batchidx, (x, y) in enumerate(my_dataset_loader):\n",
    "            pred = model(x)\n",
    "            loss=criterion(y.view(x.size(0),-1),pred)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss\n",
    "        # if epoch % 10==0:\n",
    "        #     print(total_loss.data.numpy())\n",
    "\n",
    "        print(total_loss.data.numpy())\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = test_train(act_layer = nn.ReLU(), init_method = nn.init.normal_, optimizer = optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(torch.from_numpy(test_features.astype(np.float32))).detach().numpy()\n",
    "y_pred[y_pred<0.5] = 0\n",
    "y_pred[y_pred!=0] = 1\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.96677173 0.99701689] \n",
      "recall: [0.98804992 0.99156894] \n",
      "F1 score: [0.97729502 0.99428545] \n",
      "accuracy: 0.9908690449793542\n"
     ]
    }
   ],
   "source": [
    "precision, recall, F1_score, _ = precision_recall_fscore_support(test_labels, y_pred, average=None)\n",
    "acc = accuracy_score(test_labels, y_pred)\n",
    "print(\"precision: {} \\nrecall: {} \\nF1 score: {} \\naccuracy: {}\".format(precision, recall, F1_score, acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上展示的是我们用 train(act_layer = nn.ReLU(), init_method = nn.init.normal_, optimizer = optim.Adam) 经过 1 个 epoch 得到的结果，\n",
    "\n",
    "precision: [0.96677173 0.99701689] \n",
    "recall: [0.98804992 0.99156894] \n",
    "F1 score: [0.97729502 0.99428545] \n",
    "accuracy: 0.9908690449793542\n",
    "\n",
    "已经可以简单用于说明结果，所以我们设置 epoch = 1 来进行 8 组组合的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU() <function normal_ at 0x000001E40380E670> <class 'torch.optim.adam.Adam'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Xavier\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.         0.80111051] \n",
      "recall: [0. 1.] \n",
      "F1 score: [0.         0.88957397] \n",
      "accuracy: 0.8011105105098968\n",
      "ReLU() <function normal_ at 0x000001E40380E670> <class 'torch.optim.sgd.SGD'>\n",
      "precision: [1.        0.8011187] \n",
      "recall: [5.13761091e-05 1.00000000e+00] \n",
      "F1 score: [1.02746939e-04 8.89579013e-01] \n",
      "accuracy: 0.8011207286780041\n",
      "ReLU() <function kaiming_normal_ at 0x000001E40380ED30> <class 'torch.optim.adam.Adam'>\n",
      "precision: [0.45945126 0.98782353] \n",
      "recall: [0.96433471 0.71832869] \n",
      "F1 score: [0.62237556 0.83179211] \n",
      "accuracy: 0.7672566977537401\n",
      "ReLU() <function kaiming_normal_ at 0x000001E40380ED30> <class 'torch.optim.sgd.SGD'>\n",
      "precision: [0.25309849 0.98640663] \n",
      "recall: [0.98453065 0.27868919] \n",
      "F1 score: [0.40267833 0.43459296] \n",
      "accuracy: 0.4190736413157322\n",
      "Sigmoid() <function normal_ at 0x000001E40380E670> <class 'torch.optim.adam.Adam'>\n",
      "precision: [0.97792252 0.99856805] \n",
      "recall: [0.99425615 0.99442734] \n",
      "F1 score: [0.9860217  0.99649339] \n",
      "accuracy: 0.9943932911595474\n",
      "Sigmoid() <function normal_ at 0x000001E40380E670> <class 'torch.optim.sgd.SGD'>\n",
      "precision: [0.14175307 0.79268503] \n",
      "recall: [0.09159333 0.86232248] \n",
      "F1 score: [0.11128207 0.82603869] \n",
      "accuracy: 0.7090325540617729\n",
      "Sigmoid() <function kaiming_normal_ at 0x000001E40380ED30> <class 'torch.optim.adam.Adam'>\n",
      "precision: [0.97660616 0.99959726] \n",
      "recall: [0.99838679 0.99406255] \n",
      "F1 score: [0.98737637 0.99682222] \n",
      "accuracy: 0.9949225922675035\n",
      "Sigmoid() <function kaiming_normal_ at 0x000001E40380ED30> <class 'torch.optim.sgd.SGD'>\n",
      "precision: [0.         0.80111051] \n",
      "recall: [0. 1.] \n",
      "F1 score: [0.         0.88957397] \n",
      "accuracy: 0.8011105105098968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Xavier\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def train(act_layer = nn.ReLU(), init_method = nn.init.normal_, optimizer = optim.Adam):\n",
    "    print(act_layer, init_method, optimizer)\n",
    "    epochs = 1\n",
    "    lr = 1e-3\n",
    "    model = mynet(act_layer, init_method)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optimizer(model.parameters(), lr=lr)\n",
    "    # print(model)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # print(epoch)\n",
    "        total_loss = 0\n",
    "        for batchidx, (x, y) in enumerate(my_dataset_loader):\n",
    "            pred = model(x)\n",
    "            loss=criterion(y.view(x.size(0),-1),pred)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss\n",
    "        # if epoch % 10==0:\n",
    "        #     print(total_loss.data.numpy())\n",
    "\n",
    "        # print(total_loss.data.numpy())\n",
    "    \n",
    "    y_pred = model(torch.from_numpy(test_features.astype(np.float32))).detach().numpy()\n",
    "    y_pred[y_pred<0.5] = 0\n",
    "    y_pred[y_pred!=0] = 1\n",
    "    \n",
    "    precision, recall, F1_score, _ = precision_recall_fscore_support(test_labels, y_pred, average=None)\n",
    "    acc = accuracy_score(test_labels, y_pred)\n",
    "    print(\"precision: {} \\nrecall: {} \\nF1 score: {} \\naccuracy: {}\".format(precision, recall, F1_score, acc))\n",
    "\n",
    "    return model\n",
    "\n",
    "for act_layer in (nn.ReLU(), nn.Sigmoid()):\n",
    "    for init_method in (nn.init.normal_, nn.init.kaiming_normal_):\n",
    "        for optimizer in (optim.Adam, optim.SGD):\n",
    "            train(act_layer, init_method, optimizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初步实验，结果显示在我们的网络中：\n",
    "\n",
    "激活函数： Sigmoid 一般比 ReLU 效果更好，\n",
    "\n",
    "初始化： Sigmoid + kaiming 效果好，ReLU 则是 normal 效果好\n",
    "\n",
    "优化器：Adam 一般比 SGD 效果更好\n",
    "\n",
    "最优的组合是 Sigmoid + kaiming + Adam, 达到很高的 p, r 以及最终正确率如下：\n",
    "\n",
    "precision: [0.97660616 0.99959726] \n",
    "\n",
    "recall: [0.99838679 0.99406255] \n",
    "\n",
    "F1 score: [0.98737637 0.99682222] \n",
    "\n",
    "accuracy: 0.9949225922675035"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全部结果：\n",
    "\n",
    "ReLU() <function normal_ at 0x000001E40380E670> <class 'torch.optim.adam.Adam'>\n",
    "\n",
    "precision: [0.         0.80111051] \n",
    "\n",
    "recall: [0. 1.] \n",
    "\n",
    "F1 score: [0.         0.88957397] \n",
    "\n",
    "accuracy: 0.8011105105098968\n",
    "\n",
    "ReLU() <function normal_ at 0x000001E40380E670> <class 'torch.optim.sgd.SGD'>\n",
    "\n",
    "precision: [1.        0.8011187] \n",
    "\n",
    "recall: [5.13761091e-05 1.00000000e+00] \n",
    "\n",
    "F1 score: [1.02746939e-04 8.89579013e-01] \n",
    "\n",
    "accuracy: 0.8011207286780041\n",
    "\n",
    "ReLU() <function kaiming_normal_ at 0x000001E40380ED30> <class 'torch.optim.adam.Adam'>\n",
    "\n",
    "precision: [0.45945126 0.98782353] \n",
    "\n",
    "recall: [0.96433471 0.71832869] \n",
    "\n",
    "F1 score: [0.62237556 0.83179211] \n",
    "\n",
    "accuracy: 0.7672566977537401\n",
    "\n",
    "ReLU() <function kaiming_normal_ at 0x000001E40380ED30> <class 'torch.optim.sgd.SGD'>\n",
    "\n",
    "precision: [0.25309849 0.98640663] \n",
    "\n",
    "recall: [0.98453065 0.27868919] \n",
    "\n",
    "F1 score: [0.40267833 0.43459296] \n",
    "\n",
    "accuracy: 0.4190736413157322\n",
    "\n",
    "Sigmoid() <function normal_ at 0x000001E40380E670> <class 'torch.optim.adam.Adam'>\n",
    "\n",
    "precision: [0.97792252 0.99856805] \n",
    "\n",
    "recall: [0.99425615 0.99442734] \n",
    "\n",
    "F1 score: [0.9860217  0.99649339] \n",
    "\n",
    "accuracy: 0.9943932911595474\n",
    "\n",
    "Sigmoid() <function normal_ at 0x000001E40380E670> <class 'torch.optim.sgd.SGD'>\n",
    "\n",
    "precision: [0.14175307 0.79268503] \n",
    "\n",
    "recall: [0.09159333 0.86232248] \n",
    "\n",
    "F1 score: [0.11128207 0.82603869] \n",
    "\n",
    "accuracy: 0.7090325540617729\n",
    "\n",
    "Sigmoid() <function kaiming_normal_ at 0x000001E40380ED30> <class 'torch.optim.adam.Adam'>\n",
    "\n",
    "precision: [0.97660616 0.99959726] \n",
    "\n",
    "recall: [0.99838679 0.99406255] \n",
    "\n",
    "F1 score: [0.98737637 0.99682222] \n",
    "\n",
    "accuracy: 0.9949225922675035\n",
    "\n",
    "Sigmoid() <function kaiming_normal_ at 0x000001E40380ED30> <class 'torch.optim.sgd.SGD'>\n",
    "\n",
    "precision: [0.         0.80111051] \n",
    "\n",
    "recall: [0. 1.] \n",
    "\n",
    "F1 score: [0.         0.88957397] \n",
    "\n",
    "accuracy: 0.8011105105098968"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c980b9862ab41f9934730dade093e3b6a0fcd7b9370dcc413140867050c66a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
