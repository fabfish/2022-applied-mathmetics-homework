{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1\n",
    "\n",
    "SA22011090 余致远"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高斯混合模型与 EM 算法\n",
    "\n",
    "数据集：Iris 数据集\n",
    "\n",
    "数据描述：https://www.kaggle.com/datasets/uciml/iris，可通过 sklearn 直接导入数据集\n",
    "\n",
    "任务描述：使用高斯混合模型与 EM 算法对数据进行分类计算，mixture components 设置为3。\n",
    "\n",
    "要求输出：不同高斯分布的 mean 和 variance，每个高斯分布对应的权重，plot 出分布的图。\n",
    "\n",
    "EM 算法可以参考\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html。\n",
    "\n",
    "Optional：尝试不同的 covariance structures，包括 spherical、diagonal、tied 与 full。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "gmm = GaussianMixture(n_components=3, covariance_type='full')\n",
    "# iris['feature_names']\n",
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\ell(\\theta) = \\sum_{i=1}^n \\log \\left( \\sum_{k=1}^2 \\pi_k \\underbrace{N(x_i;\\mu_k, \\sigma_k^2)}_{L[i,k]} \\right )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "class myGaussianMixture(object):\n",
    "    # mostly borrowed from https://xavierbourretsicotte.github.io/gaussian_mixture.html\n",
    "\n",
    "    def __init__(self, n_components = 3, max_iter = 100, tol = 0.001):\n",
    "\n",
    "        # Parameters\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "        # Attributes\n",
    "        self.means_ = None\n",
    "        self.covariances_ = None\n",
    "\n",
    "        self.log_likelihoods = []\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "\n",
    "        n,d = X.shape           # [150, 4]\n",
    "        k = self.n_components   # 3 types\n",
    "\n",
    "        # initialize means\n",
    "        mu = X[np.random.choice(n,k,replace = False)]   # [points=150, types=3]\n",
    "\n",
    "        # initialize a covariance matrix for each gaussian, uppercase for mat\n",
    "        Sigma = [np.eye(d)] * k                         # k=3 types * [eye(features=4)]\n",
    "\n",
    "        # initialize the probability for each gaussian pi\n",
    "        pi = np.array([1 / k] * k)                      # when summing up, count \\sum pi*P\n",
    "\n",
    "        # initialize responsibility matrix: n points for each gaussian\n",
    "        W = np.zeros((n,k))                             # [points=150, types=3]\n",
    "\n",
    "        # initialize list of log-likelihoods\n",
    "        log_likelihoods = []\n",
    "        \n",
    "        iter = 0\n",
    "        while iter < self.max_iter:\n",
    "\n",
    "            # E-step\n",
    "\n",
    "            # lambda function for gaussian pdf\n",
    "            P = lambda m, s: multivariate_normal.pdf(X, mean = m, cov = s, allow_singular=True)\n",
    "            \n",
    "            # nominator of responsibilities: j is the j-th gaussian\n",
    "            # for each node, count the expectation of belonging to type j\n",
    "            for j in range(k):\n",
    "                W[:, j] = pi[j] * P(mu[j], Sigma[j])\n",
    "\n",
    "            # log likelihood computation (same as nominator of responsibilities)    \n",
    "            l = np.sum(np.log(np.sum(W, axis = 1)))\n",
    "\n",
    "            # store log likelihood in list\n",
    "            log_likelihoods.append(l)\n",
    "\n",
    "            # compute W matrix by dividing by denominator (the sum along j) \n",
    "            W = (W.T / W.sum(axis = 1)).T\n",
    "\n",
    "            # sum of w^i entries along j (used for parameter updates)\n",
    "            # these are the soft weighted number of datapoints belonging to each gaussian\n",
    "            W_sum = np.sum(W, axis = 0)\n",
    "\n",
    "\n",
    "            # M step\n",
    "\n",
    "            for j in range(k):\n",
    "\n",
    "                ## Update means\n",
    "                mu[j] = (1. / W_sum[j]) * np.sum(W[:, j] * X.T, axis = 1).T \n",
    "\n",
    "                ## Update covariances\n",
    "                Sigma[j] = ((W[:,j] * ((X - mu[j]).T)) @ (X - mu[j])) / W_sum[j]\n",
    "\n",
    "                ## Update probabilities of each gaussian\n",
    "                pi[j] = W_sum[j] / n\n",
    "\n",
    "            # check for convergence\n",
    "            if len(log_likelihoods) < 2: continue\n",
    "            if np.abs(l - log_likelihoods[-2]) < self.tol: break\n",
    "\n",
    "        self.means_ = mu\n",
    "        self.covariances_ = Sigma\n",
    "        self.log_likelihoods = log_likelihoods\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probs = np.array([ multivariate_normal.pdf(X, mean = self.means_[j], cov = self.covariances_[j]) for j in range(self.n_components) ])\n",
    "        return np.argmax(probs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import ListedColormap\n",
    "# from matplotlib import patches\n",
    "\n",
    "X = features\n",
    "gmm = myGaussianMixture()\n",
    "gmm.fit(X)\n",
    "y = gmm.predict(X)\n",
    "print(y)\n",
    "\n",
    "print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c980b9862ab41f9934730dade093e3b6a0fcd7b9370dcc413140867050c66a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
